{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from os import path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.txt', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>turn1</th>\n",
       "      <th>turn2</th>\n",
       "      <th>turn3</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Don't worry  I'm girl</td>\n",
       "      <td>hmm how do I know if you are</td>\n",
       "      <td>What's ur name?</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>When did I?</td>\n",
       "      <td>saw many times i think -_-</td>\n",
       "      <td>No. I never saw you</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>By</td>\n",
       "      <td>by Google Chrome</td>\n",
       "      <td>Where you live</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>U r ridiculous</td>\n",
       "      <td>I might be ridiculous but I am telling the truth.</td>\n",
       "      <td>U little disgusting whore</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Just for time pass</td>\n",
       "      <td>wt do u do 4 a living then</td>\n",
       "      <td>Maybe</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                  turn1  \\\n",
       "0   0  Don't worry  I'm girl   \n",
       "1   1            When did I?   \n",
       "2   2                     By   \n",
       "3   3         U r ridiculous   \n",
       "4   4     Just for time pass   \n",
       "\n",
       "                                               turn2  \\\n",
       "0                       hmm how do I know if you are   \n",
       "1                         saw many times i think -_-   \n",
       "2                                   by Google Chrome   \n",
       "3  I might be ridiculous but I am telling the truth.   \n",
       "4                         wt do u do 4 a living then   \n",
       "\n",
       "                       turn3   label  \n",
       "0            What's ur name?  others  \n",
       "1        No. I never saw you   angry  \n",
       "2             Where you live  others  \n",
       "3  U little disgusting whore   angry  \n",
       "4                      Maybe  others  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "others    14948\n",
       "angry      5506\n",
       "sad        5463\n",
       "happy      4243\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size = 0.2, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X_train_text = train.apply(lambda x: x[1] + ' ' + x[2] + ' ' + x[3], axis = 1)\n",
    "X_train_text = train.apply(lambda x: x[1] + ' ' + x[3], axis = 1)\n",
    "#X_train_text = train.apply(lambda x: x[3], axis = 1)\n",
    "y_train = train.label\n",
    "\n",
    "#X_test_text = test.apply(lambda x: x[1] + ' ' + x[2] + ' ' + x[3], axis = 1)\n",
    "X_test_text = test.apply(lambda x: x[1] + ' ' + x[3], axis = 1)\n",
    "#X_test_text = test.apply(lambda x: x[3], axis = 1)\n",
    "y_test = test.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28481                            upgrade then i'll message\n",
       "26481                                    cool Cya good nyt\n",
       "23794    I am having something that u know Jb song i li...\n",
       "11281    Author name like that Hey that is author name yar\n",
       "23951                                With me I am Ur crush\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def text_prepare(text):\n",
    "    text = text.lower()\n",
    "    text = ' '.join([x for x in text.split(' ') if x not in STOPWORDS and x != ''])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train_text.apply(text_prepare)\n",
    "X_test = X_test_text.apply(text_prepare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def tfidf_features(X_train, X_test):\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_df = 0.9, min_df = 5, ngram_range = (1,2), token_pattern = '(\\S+)')\n",
    "    \n",
    "    X_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "    X_test = tfidf_vectorizer.transform(X_test)\n",
    "    \n",
    "    return X_train, X_test, tfidf_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_tfidf, X_test_tfidf, tfidf_vocab = tfidf_features(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_reversed_vocab = {i:word for word,i in tfidf_vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3296"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tfidf_reversed_vocab.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NRC corpora features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nrc_path = '../../semeval/NRC-Sentiment-Emotion-Lexicons/'\n",
    "\n",
    "nrc_affection_file = 'affectDict.pkl'\n",
    "nrc_emotion_file = 'emotionDict.pkl'\n",
    "nrc_vad_file = 'vadDict.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(path.join(nrc_path, nrc_affection_file), 'rb') as f:\n",
    "    affectDict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_corpora(text, corpora, dim):\n",
    "    res = np.zeros((dim,))\n",
    "    for word in text:\n",
    "        if corpora.get(word) is not None:\n",
    "            res = np.vstack((res, np.array(list(corpora[word].values()))))\n",
    "    if len(res.shape) < 2:\n",
    "        return res\n",
    "    else:\n",
    "        res = res.mean(axis = 0)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_text = X_train_text.apply(word_tokenize)\n",
    "X_test_text = X_test_text.apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_affection = np.stack(X_train_text.apply(apply_corpora, corpora = affectDict, dim = 4))\n",
    "X_test_affection = np.stack(X_test_text.apply(apply_corpora, corpora = affectDict, dim = 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(path.join(nrc_path, nrc_emotion_file), 'rb') as f:\n",
    "    emotionDict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_emotion = np.stack(X_train_text.apply(apply_corpora, corpora = emotionDict, dim = 10))\n",
    "X_test_emotion = np.stack(X_test_text.apply(apply_corpora, corpora = emotionDict, dim = 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NRC VAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(path.join(nrc_path, nrc_vad_file), 'rb') as f:\n",
    "    vadDict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_vad = np.stack(X_train_text.apply(apply_corpora, corpora = vadDict, dim = 3))\n",
    "X_test_vad = np.stack(X_test_text.apply(apply_corpora, corpora = vadDict, dim = 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from manual_features import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_manual_features(text):\n",
    "    return np.array([count_pattern(text, ALL_CAPS), count_pattern(text, ELONGATED), \n",
    "                     count_punctuations(text, QE_MARKS), \n",
    "                     ending_punctuation(text, ENDING_WITH_QE)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_manual_features = np.stack(X_train_text.apply(extract_manual_features))\n",
    "X_test_manual_features = np.stack(X_test_text.apply(extract_manual_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emoticon features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_combined = sparse.hstack((X_train_tfidf, X_train_affection, X_train_emotion, \n",
    "                                  X_train_vad, X_train_manual_features))\n",
    "X_test_combined = sparse.hstack((X_test_tfidf, X_test_affection, X_test_emotion, \n",
    "                                  X_test_vad, X_test_manual_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression(C=4, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "          n_jobs=1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_classifier = OneVsRestClassifier(LogisticRegression(penalty='l2', C=4, random_state = 0))\n",
    "label_classifier.fit(X_train_combined, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy = 0.8353779840848806\n",
      "Test precision: [0.82166566 0.86284545 0.86745796 0.81643836] \n",
      "Test recall: [0.90465116 0.77983349 0.78866906 0.71893848] \n",
      "Test F1-score [0.86116382 0.81924198 0.82618935 0.76459269] \n",
      "Support: [3010 1081 1112  829]\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = label_classifier.predict(X_test_combined)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_summary = precision_recall_fscore_support(y_test, y_test_pred, labels = ['others', 'angry', 'sad', 'happy'])\n",
    "print('Test accuracy = {}'.format(test_accuracy))\n",
    "print('Test precision: {} \\nTest recall: {} \\nTest F1-score {} \\nSupport: {}'\n",
    "      .format(test_summary[0], test_summary[1], test_summary[2], test_summary[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "others    3314\n",
       "sad       1011\n",
       "angry      977\n",
       "happy      730\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_test_pred).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "others    3010\n",
       "sad       1112\n",
       "angry     1081\n",
       "happy      829\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results \n",
    "\n",
    "all 3 turns\n",
    "```\n",
    "Test accuracy = 0.8057029177718833\n",
    "Test precision: [0.79453263 0.84388186 0.8371134  0.76544944] \n",
    "Test recall: [0.89800664 0.7400555  0.73021583 0.65741858] \n",
    "Test F1-score [0.84310667 0.7885658  0.78001921 0.7073329 ] \n",
    "```\n",
    "\n",
    "turn 1 + turn 3:\n",
    "```\n",
    "Test accuracy = 0.8353779840848806\n",
    "Test precision: [0.82166566 0.86284545 0.86745796 0.81643836] \n",
    "Test recall: [0.90465116 0.77983349 0.78866906 0.71893848] \n",
    "Test F1-score [0.86116382 0.81924198 0.82618935 0.76459269] \n",
    "```\n",
    "\n",
    "turn-3 only:\n",
    "```\n",
    "Test accuracy = 0.7904509283819628\n",
    "Test precision: [0.75380022 0.83715596 0.85941043 0.84680135] \n",
    "Test recall: [0.92259136 0.67530065 0.68165468 0.60675513] \n",
    "Test F1-score [0.82969824 0.74756784 0.76028084 0.70695713] \n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
